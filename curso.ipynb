{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia está muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]\n",
    "\n",
    "\n",
    "stopwords = ['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do', 'e', 'estou', 'esta', 'esta',\n",
    "             'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa', 'o', 'outro', 'para', 'que', 'sem', 'talvez', 'tem', 'tendo',\n",
    "             'tenha', 'teve', 'tive', 'todo', 'um', 'uma', 'umas', 'uns', 'vou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texto):\n",
    "    frases_sem_stopwords = []\n",
    "    for (frase, emocao) in texto:\n",
    "        sem_stopwords = [palavra for palavra in frase.split() if palavra not in stopwords]\n",
    "        frases_sem_stopwords.append((sem_stopwords, emocao))\n",
    "    \n",
    "    return frases_sem_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sem_stopwords = remove_stopwords(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['eu', 'sou', 'admirada', 'por', 'muitos'], 'alegria'), (['me', 'sinto', 'completamente', 'amado'], 'alegria'), (['amar', 'maravilhoso'], 'alegria'), (['me', 'sentindo', 'animado', 'novamente'], 'alegria'), (['eu', 'bem', 'hoje'], 'alegria'), (['belo', 'dia', 'dirigir', 'carro', 'novo'], 'alegria'), (['dia', 'est\\xc3\\xa1', 'bonito'], 'alegria'), (['contente', 'com', 'resultado', 'teste', 'fiz', 'dia', 'ontem'], 'alegria'), (['amor', 'lindo'], 'alegria'), (['amizade', 'amor', 'vai', 'durar', 'sempre'], 'alegria'), (['amedrontado'], 'medo'), (['ele', 'me', 'ameacando', 'dias'], 'medo'), (['isso', 'me', 'deixa', 'apavorada'], 'medo'), (['este', 'lugar', 'apavorante'], 'medo'), (['se', 'perdermos', 'jogo', 'seremos', 'eliminados', 'isso', 'me', 'deixa', 'com', 'pavor'], 'medo'), (['tome', 'cuidado', 'com', 'lobisomem'], 'medo'), (['se', 'eles', 'descobrirem', 'estamos', 'encrencados'], 'medo'), (['tremendo', 'medo'], 'medo'), (['eu', 'tenho', 'medo', 'dele'], 'medo'), (['com', 'medo', 'resultado', 'dos', 'meus', 'testes'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(sem_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# melhor chamar uma lista de stopwords \n",
    "# mais completa no nltk\n",
    "\n",
    "stopwordsNLTK = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texto):\n",
    "    frases_sem_stopwords = []\n",
    "    for (frase, emocao) in texto:\n",
    "        sem_stopwords = [palavra for palavra in frase.split() if palavra not in stopwordsNLTK]\n",
    "        frases_sem_stopwords.append((sem_stopwords, emocao))\n",
    "    \n",
    "    return frases_sem_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloves/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "sem_stopwords = remove_stopwords(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admirada', 'muitos'], 'alegria'), (['sinto', 'completamente', 'amado'], 'alegria'), (['amar', 'maravilhoso'], 'alegria'), (['sentindo', 'animado', 'novamente'], 'alegria'), (['bem', 'hoje'], 'alegria'), (['belo', 'dia', 'dirigir', 'carro', 'novo'], 'alegria'), (['dia', 'est\\xc3\\xa1', 'bonito'], 'alegria'), (['contente', 'resultado', 'teste', 'fiz', 'dia', 'ontem'], 'alegria'), (['amor', 'lindo'], 'alegria'), (['amizade', 'amor', 'vai', 'durar', 'sempre'], 'alegria'), (['amedrontado'], 'medo'), (['ameacando', 'dias'], 'medo'), (['deixa', 'apavorada'], 'medo'), (['lugar', 'apavorante'], 'medo'), (['perdermos', 'outro', 'jogo', 'eliminados', 'deixa', 'pavor'], 'medo'), (['tome', 'cuidado', 'lobisomem'], 'medo'), (['descobrirem', 'encrencados'], 'medo'), (['tremendo', 'medo'], 'medo'), (['medo'], 'medo'), (['medo', 'resultado', 'testes'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(sem_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estração do Radical (Stemmer)\n",
    "\n",
    "<img src='radical.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aplicar_stemmer(texto):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frases = []\n",
    "    \n",
    "    for (frase, emocao) in sem_stopwords:\n",
    "        \n",
    "        com_stemmer = [stemmer.stem(palavra) for palavra in frase]\n",
    "        \n",
    "        frases.append((com_stemmer, emocao))\n",
    "        \n",
    "    return frases\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloves/anaconda2/lib/python2.7/site-packages/nltk/stem/rslp.py:103: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if word[-1] == \"s\":\n",
      "/home/cloves/anaconda2/lib/python2.7/site-packages/nltk/stem/rslp.py:107: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if word[-1] == \"a\":\n",
      "/home/cloves/anaconda2/lib/python2.7/site-packages/nltk/stem/rslp.py:133: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if word[-suffix_length:] == rule[0]:       # if suffix matches\n"
     ]
    }
   ],
   "source": [
    "frases = aplicar_stemmer(sem_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([u'admir', u'muit'], 'alegria'), ([u'sint', u'complet', u'am'], 'alegria'), ([u'am', u'maravilh'], 'alegria'), ([u'sent', u'anim', u'nov'], 'alegria'), (['bem', u'hoj'], 'alegria'), ([u'bel', 'dia', u'dirig', u'carr', u'nov'], 'alegria'), (['dia', 'est\\xc3\\xa1', u'bonit'], 'alegria'), ([u'cont', u'result', u'test', 'fiz', 'dia', u'ont'], 'alegria'), ([u'am', u'lind'], 'alegria'), ([u'amizad', u'am', 'vai', u'dur', u'sempr'], 'alegria'), ([u'amedront'], 'medo'), ([u'ameac', u'dia'], 'medo'), ([u'deix', u'apavor'], 'medo'), ([u'lug', u'apavor'], 'medo'), ([u'perd', u'outr', u'jog', u'elimin', u'deix', u'pav'], 'medo'), ([u'tom', u'cuid', u'lobisom'], 'medo'), ([u'descobr', u'encrenc'], 'medo'), ([u'trem', u'med'], 'medo'), ([u'med'], 'medo'), ([u'med', u'result', u'test'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando lista de todas as palavras na minha base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lista_todas_as_palavras(frases):\n",
    "    todas_palavras = []\n",
    "    for (palavras, _) in frases:\n",
    "        todas_palavras.extend(palavras)\n",
    "        \n",
    "    return todas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "todas_palavras = lista_todas_as_palavras(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'admir', u'muit', u'sint', u'complet', u'am', u'am', u'maravilh', u'sent', u'anim', u'nov', 'bem', u'hoj', u'bel', 'dia', u'dirig', u'carr', u'nov', 'dia', 'est\\xc3\\xa1', u'bonit', u'cont', u'result', u'test', 'fiz', 'dia', u'ont', u'am', u'lind', u'amizad', u'am', 'vai', u'dur', u'sempr', u'amedront', u'ameac', u'dia', u'deix', u'apavor', u'lug', u'apavor', u'perd', u'outr', u'jog', u'elimin', u'deix', u'pav', u'tom', u'cuid', u'lobisom', u'descobr', u'encrenc', u'trem', u'med', u'med', u'med', u'result', u'test']\n"
     ]
    }
   ],
   "source": [
    "print(todas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extração de Palavras Únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_frequencia(palavras):\n",
    "    return nltk.FreqDist(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequencia = busca_frequencia(todas_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'am', 4), ('dia', 4), (u'med', 3), (u'result', 2), (u'test', 2), (u'apavor', 2), (u'nov', 2), (u'deix', 2), (u'ameac', 1), (u'cont', 1), (u'amizad', 1), (u'muit', 1), (u'tom', 1), (u'bonit', 1), (u'cuid', 1), (u'ont', 1), (u'encrenc', 1), (u'outr', 1), ('vai', 1), (u'pav', 1), (u'perd', 1), ('fiz', 1), (u'maravilh', 1), (u'hoj', 1), (u'lobisom', 1), (u'lug', 1), (u'dur', 1), (u'amedront', 1), (u'sent', 1), (u'complet', 1), (u'elimin', 1), (u'anim', 1), (u'sempr', 1), (u'carr', 1), (u'sint', 1), ('est\\xc3\\xa1', 1), (u'jog', 1), (u'lind', 1), (u'trem', 1), (u'bel', 1), ('bem', 1), (u'descobr', 1), (u'admir', 1), (u'dirig', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(frequencia.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_palavras_unicas(frequencia):\n",
    "    return frequencia.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palavras_unicas = busca_palavras_unicas(frequencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ameac', u'cont', u'amizad', u'am', u'muit', u'tom', u'bonit', u'result', u'cuid', u'ont', u'encrenc', u'outr', 'vai', u'pav', u'perd', 'fiz', u'maravilh', u'hoj', u'lobisom', u'lug', u'test', u'dur', u'amedront', u'sent', u'complet', u'med', u'elimin', u'anim', u'sempr', u'carr', u'sint', u'apavor', 'est\\xc3\\xa1', u'jog', u'nov', u'lind', u'trem', u'bel', 'bem', 'dia', u'descobr', u'admir', u'dirig', u'deix']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_unicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das palavras de cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extrator_palavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavras_unicas:\n",
    "        caracteristicas['%s' %palavras] = (palavras in doc)\n",
    "        \n",
    "    return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caracteriscas_frase = extrator_palavras(['am', 'nov', 'dia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'deix': False, u'ameac': False, u'cont': False, u'amizad': False, u'am': True, u'muit': False, u'bonit': False, u'result': False, u'cuid': False, u'ont': False, u'encrenc': False, u'outr': False, 'vai': False, u'pav': False, u'perd': False, 'fiz': False, u'maravilh': False, u'hoj': False, u'carr': False, u'lug': False, u'test': False, u'dur': False, u'amedront': False, u'sent': False, u'complet': False, u'apavor': False, u'med': False, u'elimin': False, u'anim': False, u'sempr': False, u'lobisom': False, u'sint': False, u'tom': False, 'est\\xc3\\xa1': False, u'jog': False, u'nov': True, u'lind': False, u'trem': False, u'bel': False, 'bem': False, 'dia': True, u'admir': False, u'dirig': False, u'descobr': False}\n"
     ]
    }
   ],
   "source": [
    "print(caracteriscas_frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Palavras de Todas as Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basecompleta = nltk.classify.apply_features(extrator_palavras, frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({u'deix': False, u'ameac': False, u'cont': False, u'amizad': False, u'am': False, u'muit': True, u'bonit': False, u'result': False, u'cuid': False, u'ont': False, u'encrenc': False, u'outr': False, 'vai': False, u'pav': False, u'perd': False, 'fiz': False, u'maravilh': False, u'hoj': False, u'carr': False, u'lug': False, u'test': False, u'dur': False, u'amedront': False, u'sent': False, u'complet': False, u'apavor': False, u'med': False, u'elimin': False, u'anim': False, u'sempr': False, u'lobisom': False, u'sint': False, u'tom': False, 'est\\xc3\\xa1': False, u'jog': False, u'nov': False, u'lind': False, u'trem': False, u'bel': False, 'bem': False, 'dia': False, u'admir': True, u'dirig': False, u'descobr': False}, 'alegria')\n"
     ]
    }
   ],
   "source": [
    "print basecompleta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Aplicando Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(basecompleta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alegria', 'medo']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     dia = True           alegri : medo   =      2.3 : 1.0\n",
      "                      am = False            medo : alegri =      1.6 : 1.0\n",
      "                     med = False          alegri : medo   =      1.4 : 1.0\n",
      "                     dia = False            medo : alegri =      1.3 : 1.0\n",
      "                     nov = False            medo : alegri =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classificador.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teste = \"estou com medo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos aplicar o stemmer manualmente\n",
    "def preditor(frase):\n",
    "    testestmmer = []\n",
    "    stmmer  = nltk.RSLPStemmer()\n",
    "    for palavra in frase.split():\n",
    "        testestmmer.append(stmmer.stem(palavra))\n",
    "    \n",
    "    novo = extrator_palavras(testestmmer)\n",
    "    print 'A frase é de ' + classificador.classify(novo) + '\\n'\n",
    "    \n",
    "    distribuicao = classificador.prob_classify(novo)\n",
    "    for classe in distribuicao.samples():\n",
    "        print \"%s: %f\" %(classe, distribuicao.prob(classe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase é de medo\n",
      "\n",
      "alegria: 0.037283\n",
      "medo: 0.962717\n"
     ]
    }
   ],
   "source": [
    "preditor('estou com medo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase é de alegria\n",
      "\n",
      "alegria: 0.528678\n",
      "medo: 0.471322\n"
     ]
    }
   ],
   "source": [
    "preditor('que dia feliz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase é de alegria\n",
      "\n",
      "alegria: 0.557210\n",
      "medo: 0.442790\n"
     ]
    }
   ],
   "source": [
    "preditor('estou muito feliz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase é de medo\n",
      "\n",
      "alegria: 0.275110\n",
      "medo: 0.724890\n"
     ]
    }
   ],
   "source": [
    "preditor('que coisa assustadora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase é de medo\n",
      "\n",
      "alegria: 0.275110\n",
      "medo: 0.724890\n"
     ]
    }
   ],
   "source": [
    "preditor(\"felizmente deu tudo certo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
